{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d537d09-e563-40c0-97e0-2b1bfe39cbac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark import SparkContext, SparkConf\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Union\").master(\"local[*]\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c12883f1-d2cf-4bab-af8c-574466c8a3c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"/?o=1712464757339678#setting/sparkui/0408-143655-1xf8ygvh/driver-7498859293620461514\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[8]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Databricks Shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "\n            <div>\n                <p><b>SparkSession - hive</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"/?o=1712464757339678#setting/sparkui/0408-143655-1xf8ygvh/driver-7498859293620461514\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.3.2</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[8]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Databricks Shell</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        ",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f464a1d-6e09-4f22-8f40-84a987e50dfd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data_1 = [\n",
    "    [\"000\", \"107\", \"Emily Lee\", 26, \"\", 46000, \"2019-01-01\"],\n",
    "    [\"001\", \"101\", \"John Doe\", 30, \"Male\", 50000, \"2015-01-01\"],\n",
    "    [\"002\", \"101\", \"Jane Smith\", 25, \"Female\", 45000, \"2016-02-15\"],\n",
    "    [\"003\", \"102\", \"Bob Brown\", 35, \"Male\", 55000, \"2014-05-01\"],\n",
    "    [\"004\", \"102\", \"Alice Lee\", 28, \"Female\", 48000, \"2017-09-30\"],\n",
    "    [\"005\", \"103\", \"Jack Chan\", 40, \"Male\", 60000, \"2013-04-01\"],\n",
    "    [\"006\", \"103\", \"Jill Wong\", 32, \"Female\", 52000, \"2018-07-01\"],\n",
    "    [\"007\", \"101\", \"James Johnson\", 42, \"Male\", 70000, \"2012-03-15\"],\n",
    "    [\"008\", \"102\", \"Kate Kim\", 29, \"Female\", 51000, \"2019-10-01\"],\n",
    "    [\"009\", \"103\", \"Tom Tan\", 33, \"Male\", 58000, \"2016-06-01\"],\n",
    "    [\"010\", \"104\", \"Lisa Lee\", 27, \"Female\", 47000, \"2018-08-01\"],\n",
    "    ]\n",
    "\n",
    "data_2 = [\n",
    "    [\"011\", \"104\", \"David Park\", 38, \"Male\", 65000, \"2015-11-01\"],\n",
    "    [\"012\", \"105\", \"Susan Chen\", 31, \"Female\", 54000, \"2017-02-15\"],\n",
    "    [\"013\", \"106\", \"Brian Kim\", 45, \"Male\", 75000, \"2011-07-01\"],\n",
    "    [\"014\", \"107\", \"Emily Lee\", 26, \"Female\", 46000, \"2019-01-01\"],\n",
    "    [\"015\", \"106\", \"Michael Lee\", 37, \"Male\", 63000, \"2014-09-30\"],\n",
    "    [\"016\", \"107\", \"Kelly Zhang\", 30, \"Female\", 49000, \"2018-04-01\"],\n",
    "    [\"017\", \"105\", \"George Wang\", 34, \"Male\", 57000, \"2016-03-15\"],\n",
    "    [\"018\", \"104\", \"Nancy Liu\", 29, \"Female\", 50000, \"2017-06-01\"],\n",
    "    [\"019\", \"103\", \"Steven Chen\", 36, \"Male\", 62000, \"2015-08-01\"],\n",
    "    [\"020\", \"102\", \"Grace Kim\", 32, \"Female\", 53000, \"2018-11-01\"],\n",
    "]\n",
    "\n",
    "emp_schema = \"employee_id string, department_id string, name string, age string, gender string, salary string, hire_date string\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dcac795d-7402-4d92-bfa4-f1c50118511e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------------+---+------+------+----------+\n|employee_id|department_id|         name|age|gender|salary| hire_date|\n+-----------+-------------+-------------+---+------+------+----------+\n|        000|          107|    Emily Lee| 26|      | 46000|2019-01-01|\n|        001|          101|     John Doe| 30|  Male| 50000|2015-01-01|\n|        002|          101|   Jane Smith| 25|Female| 45000|2016-02-15|\n|        003|          102|    Bob Brown| 35|  Male| 55000|2014-05-01|\n|        004|          102|    Alice Lee| 28|Female| 48000|2017-09-30|\n|        005|          103|    Jack Chan| 40|  Male| 60000|2013-04-01|\n|        006|          103|    Jill Wong| 32|Female| 52000|2018-07-01|\n|        007|          101|James Johnson| 42|  Male| 70000|2012-03-15|\n|        008|          102|     Kate Kim| 29|Female| 51000|2019-10-01|\n|        009|          103|      Tom Tan| 33|  Male| 58000|2016-06-01|\n|        010|          104|     Lisa Lee| 27|Female| 47000|2018-08-01|\n+-----------+-------------+-------------+---+------+------+----------+\n\n+-----------+-------------+-----------+---+------+------+----------+\n|employee_id|department_id|       name|age|gender|salary| hire_date|\n+-----------+-------------+-----------+---+------+------+----------+\n|        011|          104| David Park| 38|  Male| 65000|2015-11-01|\n|        012|          105| Susan Chen| 31|Female| 54000|2017-02-15|\n|        013|          106|  Brian Kim| 45|  Male| 75000|2011-07-01|\n|        014|          107|  Emily Lee| 26|Female| 46000|2019-01-01|\n|        015|          106|Michael Lee| 37|  Male| 63000|2014-09-30|\n|        016|          107|Kelly Zhang| 30|Female| 49000|2018-04-01|\n|        017|          105|George Wang| 34|  Male| 57000|2016-03-15|\n|        018|          104|  Nancy Liu| 29|Female| 50000|2017-06-01|\n|        019|          103|Steven Chen| 36|  Male| 62000|2015-08-01|\n|        020|          102|  Grace Kim| 32|Female| 53000|2018-11-01|\n+-----------+-------------+-----------+---+------+------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "emp_data_1 = spark.createDataFrame(data_1,schema=emp_schema)\n",
    "emp_data_2 = spark.createDataFrame(data_2,schema= emp_schema)\n",
    "\n",
    "emp_data_1.show()\n",
    "emp_data_2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69044f61-7dc3-459a-9e6e-fb641d8be9b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- employee_id: string (nullable = true)\n |-- department_id: string (nullable = true)\n |-- name: string (nullable = true)\n |-- age: string (nullable = true)\n |-- gender: string (nullable = true)\n |-- salary: string (nullable = true)\n |-- hire_date: string (nullable = true)\n\nroot\n |-- employee_id: string (nullable = true)\n |-- department_id: string (nullable = true)\n |-- name: string (nullable = true)\n |-- age: string (nullable = true)\n |-- gender: string (nullable = true)\n |-- salary: string (nullable = true)\n |-- hire_date: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "emp_data_1.printSchema()\n",
    "emp_data_2.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f6dd264b-7835-426e-adbd-324d33599770",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# UNION\n",
    "## Union used to combine both tables and that both the tables should have same schema, Columns should be same and column sequences should same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e6215a30-99fb-413f-913e-ec57612fb4f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Incase of Union only distinct values will be given no duplicates, but incase of unionall all the values from both the tables are given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ba2f65c-007c-4287-942c-e13844058598",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------------+---+------+------+----------+\n|employee_id|department_id|         name|age|gender|salary| hire_date|\n+-----------+-------------+-------------+---+------+------+----------+\n|        000|          107|    Emily Lee| 26|      | 46000|2019-01-01|\n|        001|          101|     John Doe| 30|  Male| 50000|2015-01-01|\n|        002|          101|   Jane Smith| 25|Female| 45000|2016-02-15|\n|        003|          102|    Bob Brown| 35|  Male| 55000|2014-05-01|\n|        004|          102|    Alice Lee| 28|Female| 48000|2017-09-30|\n|        005|          103|    Jack Chan| 40|  Male| 60000|2013-04-01|\n|        006|          103|    Jill Wong| 32|Female| 52000|2018-07-01|\n|        007|          101|James Johnson| 42|  Male| 70000|2012-03-15|\n|        008|          102|     Kate Kim| 29|Female| 51000|2019-10-01|\n|        009|          103|      Tom Tan| 33|  Male| 58000|2016-06-01|\n|        010|          104|     Lisa Lee| 27|Female| 47000|2018-08-01|\n|        011|          104|   David Park| 38|  Male| 65000|2015-11-01|\n|        012|          105|   Susan Chen| 31|Female| 54000|2017-02-15|\n|        013|          106|    Brian Kim| 45|  Male| 75000|2011-07-01|\n|        014|          107|    Emily Lee| 26|Female| 46000|2019-01-01|\n|        015|          106|  Michael Lee| 37|  Male| 63000|2014-09-30|\n|        016|          107|  Kelly Zhang| 30|Female| 49000|2018-04-01|\n|        017|          105|  George Wang| 34|  Male| 57000|2016-03-15|\n|        018|          104|    Nancy Liu| 29|Female| 50000|2017-06-01|\n|        019|          103|  Steven Chen| 36|  Male| 62000|2015-08-01|\n+-----------+-------------+-------------+---+------+------+----------+\nonly showing top 20 rows\n\n+-----------+-------------+-------------+---+------+------+----------+\n|employee_id|department_id|         name|age|gender|salary| hire_date|\n+-----------+-------------+-------------+---+------+------+----------+\n|        000|          107|    Emily Lee| 26|      | 46000|2019-01-01|\n|        001|          101|     John Doe| 30|  Male| 50000|2015-01-01|\n|        002|          101|   Jane Smith| 25|Female| 45000|2016-02-15|\n|        003|          102|    Bob Brown| 35|  Male| 55000|2014-05-01|\n|        004|          102|    Alice Lee| 28|Female| 48000|2017-09-30|\n|        005|          103|    Jack Chan| 40|  Male| 60000|2013-04-01|\n|        006|          103|    Jill Wong| 32|Female| 52000|2018-07-01|\n|        007|          101|James Johnson| 42|  Male| 70000|2012-03-15|\n|        008|          102|     Kate Kim| 29|Female| 51000|2019-10-01|\n|        009|          103|      Tom Tan| 33|  Male| 58000|2016-06-01|\n|        010|          104|     Lisa Lee| 27|Female| 47000|2018-08-01|\n|        011|          104|   David Park| 38|  Male| 65000|2015-11-01|\n|        012|          105|   Susan Chen| 31|Female| 54000|2017-02-15|\n|        013|          106|    Brian Kim| 45|  Male| 75000|2011-07-01|\n|        014|          107|    Emily Lee| 26|Female| 46000|2019-01-01|\n|        015|          106|  Michael Lee| 37|  Male| 63000|2014-09-30|\n|        016|          107|  Kelly Zhang| 30|Female| 49000|2018-04-01|\n|        017|          105|  George Wang| 34|  Male| 57000|2016-03-15|\n|        018|          104|    Nancy Liu| 29|Female| 50000|2017-06-01|\n|        019|          103|  Steven Chen| 36|  Male| 62000|2015-08-01|\n+-----------+-------------+-------------+---+------+------+----------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "emp = emp_data_1.union(emp_data_2)\n",
    "emp.show()\n",
    "emp_unionAll = emp_data_1.unionAll(emp_data_2).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a67c43f2-292e-4a21-ae9a-45250b99d9b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Sort the employees based on salary desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e71d376-0ce0-41b0-9029-9ebb9d7136d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------------+---+------+------+----------+\n|employee_id|department_id|         name|age|gender|salary| hire_date|\n+-----------+-------------+-------------+---+------+------+----------+\n|        013|          106|    Brian Kim| 45|  Male| 75000|2011-07-01|\n|        007|          101|James Johnson| 42|  Male| 70000|2012-03-15|\n|        011|          104|   David Park| 38|  Male| 65000|2015-11-01|\n|        015|          106|  Michael Lee| 37|  Male| 63000|2014-09-30|\n|        019|          103|  Steven Chen| 36|  Male| 62000|2015-08-01|\n|        005|          103|    Jack Chan| 40|  Male| 60000|2013-04-01|\n|        009|          103|      Tom Tan| 33|  Male| 58000|2016-06-01|\n|        017|          105|  George Wang| 34|  Male| 57000|2016-03-15|\n|        003|          102|    Bob Brown| 35|  Male| 55000|2014-05-01|\n|        012|          105|   Susan Chen| 31|Female| 54000|2017-02-15|\n|        020|          102|    Grace Kim| 32|Female| 53000|2018-11-01|\n|        006|          103|    Jill Wong| 32|Female| 52000|2018-07-01|\n|        008|          102|     Kate Kim| 29|Female| 51000|2019-10-01|\n|        018|          104|    Nancy Liu| 29|Female| 50000|2017-06-01|\n|        001|          101|     John Doe| 30|  Male| 50000|2015-01-01|\n|        016|          107|  Kelly Zhang| 30|Female| 49000|2018-04-01|\n|        004|          102|    Alice Lee| 28|Female| 48000|2017-09-30|\n|        010|          104|     Lisa Lee| 27|Female| 47000|2018-08-01|\n|        014|          107|    Emily Lee| 26|Female| 46000|2019-01-01|\n|        000|          107|    Emily Lee| 26|      | 46000|2019-01-01|\n+-----------+-------------+-------------+---+------+------+----------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "emp_salary_desc = emp.orderBy(col(\"salary\").desc())\n",
    "emp_salary_desc.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab9eba2a-da9c-43ed-b88a-16b02ac86bbd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------------+---+------+------+----------+\n|employee_id|department_id|         name|age|gender|salary| hire_date|\n+-----------+-------------+-------------+---+------+------+----------+\n|        002|          101|   Jane Smith| 25|Female| 45000|2016-02-15|\n|        014|          107|    Emily Lee| 26|Female| 46000|2019-01-01|\n|        000|          107|    Emily Lee| 26|      | 46000|2019-01-01|\n|        010|          104|     Lisa Lee| 27|Female| 47000|2018-08-01|\n|        004|          102|    Alice Lee| 28|Female| 48000|2017-09-30|\n|        016|          107|  Kelly Zhang| 30|Female| 49000|2018-04-01|\n|        018|          104|    Nancy Liu| 29|Female| 50000|2017-06-01|\n|        001|          101|     John Doe| 30|  Male| 50000|2015-01-01|\n|        008|          102|     Kate Kim| 29|Female| 51000|2019-10-01|\n|        006|          103|    Jill Wong| 32|Female| 52000|2018-07-01|\n|        020|          102|    Grace Kim| 32|Female| 53000|2018-11-01|\n|        012|          105|   Susan Chen| 31|Female| 54000|2017-02-15|\n|        003|          102|    Bob Brown| 35|  Male| 55000|2014-05-01|\n|        017|          105|  George Wang| 34|  Male| 57000|2016-03-15|\n|        009|          103|      Tom Tan| 33|  Male| 58000|2016-06-01|\n|        005|          103|    Jack Chan| 40|  Male| 60000|2013-04-01|\n|        019|          103|  Steven Chen| 36|  Male| 62000|2015-08-01|\n|        015|          106|  Michael Lee| 37|  Male| 63000|2014-09-30|\n|        011|          104|   David Park| 38|  Male| 65000|2015-11-01|\n|        007|          101|James Johnson| 42|  Male| 70000|2012-03-15|\n+-----------+-------------+-------------+---+------+------+----------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "emp_salary_asc = emp.orderBy(col(\"salary\").asc()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7caf1c96-5d32-43a6-bb09-5b354e82eb1d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Aggregating the Data based on department i'd and count no.of employees in that department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "01f8d461-316b-40e8-9ee2-cca1309a3ca5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------------------+\n|department_id|total_department_count|\n+-------------+----------------------+\n|          107|                     3|\n|          101|                     3|\n|          102|                     4|\n|          103|                     4|\n|          104|                     3|\n|          105|                     2|\n|          106|                     2|\n+-------------+----------------------+\n\n"
     ]
    }
   ],
   "source": [
    "emp_aggr = emp.groupBy(\"department_id\").agg(count(\"employee_id\").alias(\"total_department_count\"))\n",
    "emp_aggr.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0ed86be2-dc68-43f8-b4a8-e401762b09d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Aggregate the data by grouping based on department i'd and sum the salaries in department wise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a07dcef-5577-4628-903d-09e1a60e3897",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------------+\n|department_id|sum_of_salaries|\n+-------------+---------------+\n|          105|       111000.0|\n|          106|       138000.0|\n|          107|       141000.0|\n|          104|       162000.0|\n|          101|       165000.0|\n|          102|       207000.0|\n|          103|       232000.0|\n+-------------+---------------+\n\n"
     ]
    }
   ],
   "source": [
    "emp_salary_group = emp.groupBy(\"department_id\").agg(sum(\"salary\").alias(\"sum_of_salaries\")).orderBy(col(\"sum_of_salaries\").asc())\n",
    "emp_salary_group.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "07864c9c-dfe9-40fe-bfcb-87b168057309",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Aggregate the data using grouping on department i'd and using having clause find the departments whose having avg.salary > 50000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f1105366-4c7f-42df-bf01-c1e528df3e3b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+\n|department_id|avg_salary|\n+-------------+----------+\n|          101|   55000.0|\n|          102|   51750.0|\n|          103|   58000.0|\n|          104|   54000.0|\n|          105|   55500.0|\n|          106|   69000.0|\n+-------------+----------+\n\n+-------------+----------+\n|department_id|avg_salary|\n+-------------+----------+\n|          101|   55000.0|\n|          102|   51750.0|\n|          103|   58000.0|\n|          104|   54000.0|\n|          105|   55500.0|\n|          106|   69000.0|\n+-------------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "emp_having = emp.groupBy(\"department_id\").agg(avg(\"salary\").alias(\"avg_salary\")).where(\"avg_salary > 50000\")\n",
    "emp_having.show()\n",
    "\n",
    "emp_having2 = emp.groupBy(\"department_id\").agg(avg(\"salary\").alias(\"avg_salary\")).filter((col(\"avg_salary\") > 50000))\n",
    "emp_having2.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e893a128-9da4-49f1-b303-037499762ecc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Using unionByName we can combine two tables even the columns are not in sequential order, unionByName matches with column name and tries to combine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a024a46d-66ae-44f6-928c-62c4f847fca2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[44]: 21"
     ]
    }
   ],
   "source": [
    "emp.count()\n",
    "# spark by default counts the no.of records in a data frame"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "5- Union, Sorting, Aggregation",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}